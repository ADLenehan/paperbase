# Final MCP Tool Optimizations

## Your Questions

1. **"Reducto output should have embedding ready data?"**
   - ‚úÖ **YES!** Reducto returns perfect chunks for embeddings

2. **"Let's triple check that the tools are 1000% easiest to use and most powerful for LLMs"**
   - ‚úÖ **OPTIMIZED!** Complete overhaul of tool definitions and responses

---

## Key Findings

### 1. Reducto Has Perfect Embedding Data! üéâ

**What Reducto Returns:**
```python
{
  "chunks": [
    {
      "id": "chunk_1",
      "content": "This is the semantic text chunk",
      "logprobs_confidence": 0.95,  # ‚úÖ Confidence per chunk!
      "page": 1,                     # ‚úÖ Page number for citations!
      "bbox": [x, y, w, h]          # ‚úÖ Bounding box for highlighting!
    }
  ]
}
```

**Why This Is Perfect:**
- ‚úÖ Already semantically chunked (Reducto optimizes boundaries)
- ‚úÖ Optimal size for embedding models
- ‚úÖ Has confidence scores per chunk
- ‚úÖ Has page/bbox for precise citations
- ‚úÖ No need to re-chunk documents!

**Action:** Use Reducto chunks DIRECTLY for vector embeddings instead of arbitrary splitting.

---

### 2. Tool Optimization for LLM Consumption

#### Before (Issues Found)

**Problem 1: Vague Descriptions**
```json
{
  "name": "search_documents",
  "description": "Search documents..."  // When do I use this vs rag_query?
}
```

**Problem 2: No Examples**
```json
{
  "description": "Execute aggregations"  // How? What for?
}
```

**Problem 3: No Workflow Guidance**
- LLMs don't know which tool to use when
- No indication of tool relationships
- Missing "next steps" after results

**Problem 4: Raw Responses**
```json
{
  "documents": [...],
  "total": 42
}
// What do I do with this?
```

#### After (Optimizations)

**‚úÖ Clear Tool Priorities**
```json
{
  "name": "rag_query",
  "priority": "PRIMARY",
  "description": "üéØ PRIMARY TOOL: Answer questions about documents..."
}
```

**‚úÖ When to Use / When NOT to Use**
```json
{
  "when_to_use": [
    "User asks: 'What is the total value?'",
    "User asks: 'Which documents mention X?'"
  ],
  "when_not_to_use": [
    "Use search_documents for finding, not reading"
  ]
}
```

**‚úÖ Concrete Examples**
```json
{
  "examples": [
    {
      "user_query": "What were Q1 revenues?",
      "tool_call": {"question": "...", "max_results": 5},
      "returns": "Answer with citations"
    }
  ]
}
```

**‚úÖ Workflow Guidance**
```json
{
  "workflow": "search_documents ‚Üí get_document_content ‚Üí analyze"
}
```

**‚úÖ Enhanced Responses with Summaries**
```json
{
  "success": true,
  "summary": "Found 42 documents matching 'invoices'",  // ‚úÖ Human-readable summary
  "documents": [...],
  "total": 42,
  "top_result_preview": {                              // ‚úÖ Quick preview
    "id": 123,
    "filename": "invoice_001.pdf",
    "excerpt": "ACME Corp - Total: $1,500..."
  },
  "next_steps": {                                      // ‚úÖ What to do next
    "to_read": "Call get_document_content(123)",
    "to_answer": "Call rag_query with specific question",
    "to_analyze": "Call multi_aggregate for statistics"
  }
}
```

---

## Tool Categorization

### üéØ PRIMARY (Use These First)

1. **`rag_query`** - Answer questions (START HERE for questions)
2. **`search_documents`** - Find documents (for filtering/listing)
3. **`get_document_content`** - Read full text (after finding)

### üìä ANALYTICS

4. **`get_dashboard_analytics`** - Overview stats
5. **`multi_aggregate`** - Custom metrics

### üîß UTILITY

6. **`list_fields`** - Discover schema
7. **`list_templates`** - Discover document types
8. **`get_document_chunks`** - Handle long docs
9. **`get_document`** - Metadata only
10. **`get_search_stats`** - System health

### üêõ DEBUG

11. **`explain_query`** - Debug queries
12. **`aggregate_field`** - Legacy (use multi_aggregate)

---

## Decision Tree for Tool Selection

```
User Input
    ‚îÇ
    ‚îú‚îÄ "What is...?" / "Tell me about..."
    ‚îÇ   ‚îî‚îÄ> rag_query (answers with citations)
    ‚îÇ
    ‚îú‚îÄ "Find..." / "Show me..." / "List..."
    ‚îÇ   ‚îî‚îÄ> search_documents ‚Üí get_document_content
    ‚îÇ
    ‚îú‚îÄ "How many...?" / "What's the count...?"
    ‚îÇ   ‚îî‚îÄ> get_dashboard_analytics
    ‚îÇ
    ‚îú‚îÄ "Calculate..." / "Total..." / "Average..."
    ‚îÇ   ‚îî‚îÄ> multi_aggregate
    ‚îÇ
    ‚îú‚îÄ "What fields exist?"
    ‚îÇ   ‚îî‚îÄ> list_fields
    ‚îÇ
    ‚îî‚îÄ "Read document #X"
        ‚îî‚îÄ> get_document_content(X)
```

---

## Optimized Workflows

### Workflow 1: Answer Question (Most Common)
```python
# User: "What were the Q1 contract values?"

# ‚úÖ ONE CALL - rag_query does everything
response = rag_query({
    "question": "What were the Q1 contract values?",
    "filters": {"template": "Contracts"}
})

# Returns:
# - AI-generated answer
# - Source citations
# - Confidence level
# - Next steps
```

### Workflow 2: Find & Analyze
```python
# User: "Find invoices over $1000 and analyze them"

# Step 1: Find
docs = search_documents({
    "query": "invoices over $1000",
    "max_results": 20
})
# Returns: List with preview + next_steps guidance

# Step 2: Read (if needed)
for doc in docs["documents"]:
    content = get_document_content(doc["id"])
    # Returns: Full text + summary + next_steps

# Step 3: Analyze content
```

### Workflow 3: Analytics
```python
# User: "Show me revenue by vendor"

# ‚úÖ ONE CALL
stats = multi_aggregate({
    "aggregations": [
        {"name": "by_vendor", "field": "vendor_name", "type": "terms"},
        {"name": "revenue", "field": "total_amount", "type": "sum"}
    ]
})
```

---

## Response Format Enhancements

### Before
```json
{
  "documents": [...],
  "total": 42
}
```

### After
```json
{
  "success": true,
  "summary": "Found 42 invoices matching your query",
  "documents": [...],
  "total": 42,
  "top_result_preview": {
    "id": 123,
    "filename": "invoice_001.pdf",
    "excerpt": "ACME Corp Invoice - $1,500"
  },
  "next_steps": {
    "to_read": "get_document_content(123)",
    "to_answer": "rag_query('specific question')",
    "to_analyze": "multi_aggregate([...])"
  }
}
```

**Benefits for LLMs:**
- Clear English summary of what was found
- Preview of top result (immediate context)
- Explicit guidance on what to do next
- Actionable next steps with examples

---

## Files Created

### 1. `MCP_TOOLS_OPTIMIZED.md`
Complete analysis and optimization guide:
- Reducto chunk findings
- Tool categorization
- Decision trees
- Workflows
- Response format improvements

### 2. `mcp-server-config-optimized.json`
Enhanced MCP tool definitions with:
- Priority levels (PRIMARY/SECONDARY/UTILITY/DEBUG)
- `when_to_use` scenarios
- `when_not_to_use` warnings
- Concrete examples
- Workflow guidance
- Related tools
- Recommended workflows section

### 3. Enhanced API Responses
Updated `mcp_search.py` to return:
- Summary field
- Top result preview
- Next steps guidance
- Content previews
- Confidence levels

---

## Implementation Summary

### Changes Made

#### 1. Tool Definitions (`mcp-server-config-optimized.json`)
- ‚úÖ Added priority levels
- ‚úÖ Added "when to use" scenarios
- ‚úÖ Added concrete examples
- ‚úÖ Added workflow guidance
- ‚úÖ Added decision tree
- ‚úÖ Categorized by use case

#### 2. Response Formats (`mcp_search.py`)
- ‚úÖ Added `summary` field to all responses
- ‚úÖ Added `next_steps` guidance
- ‚úÖ Added `top_result_preview` for searches
- ‚úÖ Added `content_preview` for document reads
- ‚úÖ Added `confidence` levels to RAG

#### 3. Documentation (`MCP_TOOLS_OPTIMIZED.md`)
- ‚úÖ Reducto chunk analysis
- ‚úÖ Tool selection guide
- ‚úÖ Common workflows
- ‚úÖ Decision trees

---

## Impact

### For LLMs Using These Tools

**Before:**
- üòï "Should I use search_documents or rag_query?"
- üòï "What do I do with these search results?"
- üòï "How do I calculate totals?"
- üòï "What fields can I search on?"

**After:**
- ‚úÖ Clear tool priorities (PRIMARY tools highlighted)
- ‚úÖ Scenarios for each tool ("Use when user asks X")
- ‚úÖ Response includes next steps
- ‚úÖ Examples show exact usage
- ‚úÖ Decision tree for tool selection

### Concrete Improvements

1. **Faster Workflows**
   - LLM knows to use `rag_query` for questions (1 call vs 3)
   - Responses suggest logical next steps

2. **Better Results**
   - Right tool for right task
   - Follow workflows instead of trial/error

3. **Easier to Use**
   - Examples show exact syntax
   - Summaries explain what happened
   - Next steps guide what to do

---

## Vector Search with Reducto Chunks

### Traditional Approach (What We'd Have Done)
```python
# ‚ùå Re-chunk document arbitrarily
chunks = split_text(full_text, size=1000, overlap=200)

# Problems:
# - Splits mid-sentence
# - Loses semantic boundaries
# - No confidence scores
# - No page/bbox info
```

### Optimized Approach (Using Reducto)
```python
# ‚úÖ Use Reducto's semantic chunks
for chunk in reducto_parse_result["chunks"]:
    embedding = embed(chunk["content"])

    index_chunk({
        "text": chunk["content"],
        "embedding": embedding,
        "confidence": chunk["logprobs_confidence"],
        "page": chunk["page"],
        "bbox": chunk["bbox"]
    })

# Benefits:
# ‚úÖ Semantic boundaries preserved
# ‚úÖ Optimal chunk size
# ‚úÖ Confidence per chunk
# ‚úÖ Citations to exact location
```

---

## Next Steps

### Immediate (Done ‚úÖ)
- ‚úÖ Optimized tool descriptions
- ‚úÖ Enhanced response formats
- ‚úÖ Created decision trees
- ‚úÖ Documented Reducto findings

### Short Term (Recommended)
1. **Replace current MCP config** with optimized version
2. **Test with LLM** (Claude Desktop) using optimized tools
3. **Implement vector search** using Reducto chunks
4. **Add vector_search MCP tool**

### Testing Checklist
```bash
# Test enhanced responses
curl localhost:8000/api/mcp/search/documents \
  -d '{"query": "test", "max_results": 1}'
# Should return: summary, top_result_preview, next_steps

# Test RAG
curl localhost:8000/api/mcp/search/rag/query \
  -d '{"question": "What documents exist?"}'
# Should return: answer, sources, confidence, next_steps

# Test content retrieval
curl localhost:8000/api/mcp/search/document/1/content
# Should return: summary, content, content_preview, next_steps
```

---

## Summary

### What We Discovered

1. **Reducto already provides perfect embedding data**
   - Semantic chunks
   - Confidence scores
   - Page/bbox for citations
   - No need to re-chunk!

2. **MCP tools needed better LLM guidance**
   - Added priorities, examples, workflows
   - Enhanced responses with summaries and next steps
   - Clear decision trees for tool selection

### Files Changed

- `mcp-server-config-optimized.json` - Enhanced tool definitions
- `backend/app/api/mcp_search.py` - Enhanced response formats
- `MCP_TOOLS_OPTIMIZED.md` - Complete optimization guide
- `FINAL_OPTIMIZATIONS.md` - This summary

### Impact

**LLMs can now:**
- ‚úÖ Choose the right tool confidently
- ‚úÖ Understand what to do with results
- ‚úÖ Follow efficient workflows
- ‚úÖ Get guidance from response next_steps

**Vector search can:**
- ‚úÖ Use Reducto's optimal chunks
- ‚úÖ Preserve semantic boundaries
- ‚úÖ Include confidence per chunk
- ‚úÖ Support precise citations

---

**Bottom Line:** Your tools are now 1000% easier for LLMs to use correctly! üéâ
